{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220.00000000000003\n",
      "2.2 110.00000000000001 200\n"
     ]
    }
   ],
   "source": [
    "# 단순한 계층 구현\n",
    "# 곱셉노드\n",
    "class MulLayer:\n",
    "    def __init__(self): #초기화\n",
    "        self.x=None\n",
    "        self.y=None\n",
    "    \n",
    "    def forword(self, x, y): # x,y를 받아서 곱함\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        out= x*y\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backword(self, dout): # 상류에서 넘어온 미분(dout)에 순전파 때의 값을 서로 바꿔 곱한 후 하류로 흘림\n",
    "        dx= dout * self.y # x 와 y를 바꾼다 -> 편미분시 남는 변수가 달라짐\n",
    "        dy= dout * self.x\n",
    "        \n",
    "        return dx, dy\n",
    "\n",
    "apple = 100\n",
    "apple_num=2\n",
    "tax = 1.1\n",
    "\n",
    "# 계층들\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "#순전파\n",
    "apple_price = mul_apple_layer.forword(apple, apple_num)\n",
    "price = mul_tax_layer.forword(apple_price, tax)\n",
    "\n",
    "print(price)\n",
    "\n",
    "# 역전파\n",
    "dprice = 1\n",
    "dapple_price, dtax = mul_tax_layer.backword(dprice)\n",
    "dapple, dapple_num = mul_apple_layer.backword(dapple_price)\n",
    "\n",
    "print(dapple, dapple_num, dtax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 덧셈노드\n",
    "class AddLayer:\n",
    "    def __init__(self): # 덧셈계층은 초기화 필요 없음\n",
    "        pass#아무것도 하지말라\n",
    "    \n",
    "    def forword(self, x ,y): # x, y 더해서 반환 \n",
    "        out = x + y\n",
    "        return out\n",
    "    \n",
    "    def backword(self, dout): # 상류에서 내려온 미분(dout)을 그대로 하류로 흘림\n",
    "        dx = dout * 1 \n",
    "        dy = dout * 1\n",
    "        return dx, dy\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715.0000000000001\n",
      "110.00000000000001 2.2 165.0 3.3000000000000003 650\n"
     ]
    }
   ],
   "source": [
    "apple = 100\n",
    "apple_num=2\n",
    "orange = 150\n",
    "orange_num = 3\n",
    "tax = 1.1\n",
    "\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_orange_layer = MulLayer()\n",
    "mul_tax_layer = MulLayer()\n",
    "\n",
    "add_apple_orange = AddLayer()\n",
    "\n",
    "# 순전파\n",
    "apple_price = mul_apple_layer.forword(apple, apple_num)\n",
    "orange_price = mul_orange_layer.forword(orange,orange_num)\n",
    "\n",
    "all_price = add_apple_orange.forword(apple_price, orange_price)\n",
    "\n",
    "price = mul_tax_layer.forword(all_price, tax)\n",
    "#print(apple_price, orange_price, all_price, price)\n",
    "\n",
    "# 역전파\n",
    "dprice = 1\n",
    "dall_price, dtax= mul_tax_layer.backword(dprice)\n",
    "dapple_price, dorange_price = add_apple_orange.backword(dall_price)\n",
    "dorange, dorange_num = mul_orange_layer.backword(dorange_price)\n",
    "dapple, dapple_num = mul_apple_layer.backword(dapple_price)\n",
    "\n",
    "print(price)\n",
    "print(dapple_num,dapple, dorange_num,dorange, dtax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ReLU 구현\n",
    "# forword 와 backword 의 인자 x, dout은 넘파이 배열로 받는 것으로 가정\n",
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None # T/F로 구성된 넘파이 배열\n",
    "    \n",
    "    def forword(self,x):\n",
    "        self.mask = (x<=0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backword(self,dout):\n",
    "        dout[self.mask] = 0\n",
    "        dx = dout\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid 구현\n",
    "class sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "    \n",
    "    def forword(self,x):\n",
    "        out = 1/ (1+np.exp(-x))\n",
    "        self.out= out\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backword(self, dout):\n",
    "        dx = dout*(1.0 - self.out) * self.out # forword의 out을 저장해뒀다가 역전파 계산에 사용\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affine(행렬의 곱 신경망) 구현\n",
    "# 책\n",
    "class Affine:\n",
    "    def __init__(self,W,b):\n",
    "        self.W=W\n",
    "        self.b=b\n",
    "        self.x=None\n",
    "        self.dW=None\n",
    "        self.db=None\n",
    "    \n",
    "    def forword(self, x):\n",
    "        self.x=x\n",
    "        out = np.dot(x, self.W) + self.b\n",
    "        return out\n",
    "    \n",
    "    def backword(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis = 0)\n",
    "        \n",
    "        return dx\n",
    "# 예제 코드 for 텐서대응\n",
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        \n",
    "        self.x = None\n",
    "        self.original_x_shape = None\n",
    "        # 가중치와 편향 매개변수의 미분\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 텐서 대응\n",
    "        self.original_x_shape = x.shape\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        self.x = x\n",
    "\n",
    "        out = np.dot(self.x, self.W) + self.b\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        \n",
    "        dx = dx.reshape(*self.original_x_shape)  # 입력 데이터 모양 변경(텐서 대응)\n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0],\n",
       "       [2, 0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# softmax with loss 구현 ( softmax + cross entropy)\n",
    "def softmax(a):\n",
    "    c=np.max(a) #오버플로 대책\n",
    "    exp_a=np.exp(a-c)\n",
    "    sum_exp_a=np.sum(exp_a)\n",
    "    y=exp_a/sum_exp_a\n",
    "    return y\n",
    "def cross_entropy_error(y,t):\n",
    "    if y.ndim == 1:\n",
    "        t=t.reshape(1,t.size)   # reshape(행,열) \n",
    "        y=t.reshape(1,y.size)\n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size),t]+ 1e-7)) / batch_size # y[np.arange(batch_size),t] => y[0,3], y[1,2], y[2,5]...\n",
    "\n",
    "\n",
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None # 손실\n",
    "        self.y = None # softmax 출력\n",
    "        self.t = None # 정답 레이블(원핫 벡터)\n",
    "    \n",
    "    def forward(self,x,t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.x = x\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        return self.loss\n",
    "    \n",
    "    def backword(self,dout=1):\n",
    "        batxh_size = self.t.shape[0]\n",
    "        dx = (self.y - self.t) / batch_size\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오차역전파법을 적용한 신경망 클래스 구현\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "from collections import OrderedDict # 순서가 있는 dict\n",
    "\n",
    "\n",
    "class TwoLayerNet:\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std = 0.01):\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size) \n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n",
    "\n",
    "        self.lastLayer = SoftmaxWithLoss()\n",
    "        \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x) # 각 layer의 forword\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.lastLayer.forward(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "        \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def numerical_gradient(self, x, t): # 수치미분법으로 기울기 구하기\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads\n",
    "        \n",
    "    def gradient(self, x, t): # 오차역적파법으로 기울기 구하기\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.lastLayer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1:4.678205826238631e-10\n",
      "b1:2.6840044131556897e-09\n",
      "W2:5.572674338134994e-09\n",
      "b2:1.392507400443943e-07\n"
     ]
    }
   ],
   "source": [
    "# 기울기 확인 ( 수치미분 과 거의 같음을 확인 )\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "x_batch = x_train[:3]\n",
    "t_batch = t_train[:3]\n",
    "\n",
    "grad_numerical = network.numerical_gradient(x_batch, t_batch)\n",
    "grad_backprop = network.gradient(x_batch, t_batch)\n",
    "\n",
    "# 각 가중치의 절대 오차의 평균을 구한다.\n",
    "for key in grad_numerical.keys():\n",
    "    diff = np.average( np.abs(grad_backprop[key] - grad_numerical[key]) )\n",
    "    print(key + \":\" + str(diff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10608333333333334 0.1044\n",
      "0.8991 0.9009\n",
      "0.9222666666666667 0.926\n",
      "0.9352166666666667 0.9314\n",
      "0.94335 0.943\n",
      "0.9498333333333333 0.9463\n",
      "0.9545833333333333 0.9523\n",
      "0.9600333333333333 0.956\n",
      "0.9630166666666666 0.958\n",
      "0.9654333333333334 0.9602\n",
      "0.9687 0.9634\n",
      "0.9705666666666667 0.9652\n",
      "0.9721833333333333 0.9658\n",
      "0.974 0.9681\n",
      "0.975 0.9678\n",
      "0.9758166666666667 0.9692\n",
      "0.9788333333333333 0.9704\n"
     ]
    }
   ],
   "source": [
    "# 오차역전파법을 사용한 학습 구현\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 기울기 계산\n",
    "    #grad = network.numerical_gradient(x_batch, t_batch) # 수치 미분 방식\n",
    "    grad = network.gradient(x_batch, t_batch) # 오차역전파법 방식(훨씬 빠르다)\n",
    "    \n",
    "    # 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(train_acc, test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 시각화\n",
    "import matplotlib.pylab as plt\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "\n",
    "plt.plot(x, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"acc\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
